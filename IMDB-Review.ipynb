{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/devjoao/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from gensim.parsing.preprocessing import remove_stopwords\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "import re,string,unicodedata\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "import re\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./data/IMDB-Review.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loved today's show!!! It was a variety and not...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               50000     50000\n",
       "unique                                              49582         2\n",
       "top     Loved today's show!!! It was a variety and not...  negative\n",
       "freq                                                    5     25000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    25000\n",
       "positive    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting Sample\n",
    "X = df['review'][:2000]\n",
    "y = df['sentiment'][:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the sample into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.333, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1334,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization\n",
    "tk = ToktokTokenizer()\n",
    "\n",
    "#English stopwords\n",
    "english_stops = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "717     I want very much to believe that the above quo...\n",
       "1649    This is an interesting movie I think its very ...\n",
       "1079    I have to say the first I watched this film wa...\n",
       "1983    I saw this with few expectations and absolutel...\n",
       "542     The first Cube movie was an art movie It set u...\n",
       "                              ...                        \n",
       "835     The story has been told before A deadly diseas...\n",
       "1216    Mickey Rourke hunts Diane Lane in Elmore Leona...\n",
       "1653    Yeah that about sums it up This movie was horr...\n",
       "559     So I rented this from Netflix because somebody...\n",
       "684     The perfect murder is foiled when a wifeplayed...\n",
       "Name: review, Length: 1334, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Text Cleaning\n",
    "def strip_html(text):\n",
    "    clean = re.compile('<.*?>')\n",
    "    return re.sub(clean, '', text)\n",
    "\n",
    "def remove_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "\n",
    "def clean_character(text):\n",
    "    pattern = r'[^a-zA-z0-9\\s]'\n",
    "    return re.sub(pattern,'',text)\n",
    "\n",
    "def clean_content(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_square_brackets(text)\n",
    "    text = clean_character(text)\n",
    "    return text\n",
    "\n",
    "X_train = X_train.apply(clean_content)\n",
    "X_test = X_test.apply(clean_content)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "717     I want veri much to believ that the abov quot ...\n",
       "1649    thi is an interest movi I think it veri humor ...\n",
       "1079    I have to say the first I watch thi film wa ab...\n",
       "1983    I saw thi with few expect and absolut love it ...\n",
       "542     the first cube movi wa an art movi It set up a...\n",
       "                              ...                        \n",
       "835     the stori ha been told befor A deadli diseas i...\n",
       "1216    mickey rourk hunt dian lane in elmor leonard k...\n",
       "1653    yeah that about sum it up thi movi wa horrifi ...\n",
       "559     So I rent thi from netflix becaus somebodi gav...\n",
       "684     the perfect murder is foil when a wifeplay by ...\n",
       "Name: review, Length: 1334, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stemming\n",
    "def stemmer(text):\n",
    "    port = PorterStemmer()\n",
    "    text = ' '.join([port.stem(word) for word in text.split()])\n",
    "    return text\n",
    "\n",
    "#Apply function on review column\n",
    "X_train = X_train.apply(stemmer)\n",
    "X_test = X_test.apply(stemmer)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "717     I want veri believ abov quot specif english su...\n",
       "1649    thi movi I think veri humor humor veri black f...\n",
       "1079    I I watch thi film wa 6 year ago I actual enjo...\n",
       "1983    I saw thi expect absolut love bend like beckha...\n",
       "542     cube movi wa art movi It set world major arche...\n",
       "                              ...                        \n",
       "835     stori ha told befor A deadli diseas spread ext...\n",
       "1216    mickey rourk hunt dian lane elmor leonard kill...\n",
       "1653    yeah sum thi movi wa horrifi minut I want goug...\n",
       "559     So I rent thi netflix becaus somebodi gave rog...\n",
       "684     perfect murder foil wifeplay mari ellen traino...\n",
       "Name: review, Length: 1334, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stopwords with Gensim lib\n",
    "def remove_with_gensim(text):\n",
    "    return remove_stopwords(text)\n",
    "\n",
    "X_train = X_train.apply(remove_with_gensim)\n",
    "X_test = X_test.apply(remove_with_gensim)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf_train: (1334, 260479)\n",
      "Tfidf_test: (666, 260479)\n"
     ]
    }
   ],
   "source": [
    "#Tfidf vectorizer\n",
    "tf=TfidfVectorizer(min_df=0,max_df=1,use_idf=True,ngram_range=(1,3))\n",
    "\n",
    "#transformed train reviews\n",
    "train_reviews=tf.fit_transform(X_train)\n",
    "\n",
    "#transformed test reviews\n",
    "test_reviews=tf.transform(X_test)\n",
    "\n",
    "print('Tfidf_train:',train_reviews.shape)\n",
    "print('Tfidf_test:',test_reviews.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=400, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=42, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "LogisticRegression(C=1, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=400, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=42, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/devjoao/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Logistc Regressor\n",
    "regressor = LogisticRegression(penalty='l2',max_iter=400,C=1,random_state=42)\n",
    "\n",
    "#Fitting the model for TF\n",
    "regressor_bow = regressor.fit(train_reviews, y_train)\n",
    "print(regressor_bow)\n",
    "#Fitting the model for tfidf features\n",
    "lr_tfidf = regressor.fit(train_reviews,y_train)\n",
    "print(lr_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'negative'\n",
      " 'positive' 'positive' 'negative' 'negative' 'negative' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'negative' 'positive'\n",
      " 'negative' 'positive' 'positive' 'positive' 'negative' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'negative' 'positive'\n",
      " 'positive' 'positive' 'negative' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'negative' 'positive' 'negative'\n",
      " 'positive' 'positive' 'negative' 'positive' 'negative' 'negative'\n",
      " 'positive' 'positive' 'positive' 'negative' 'negative' 'positive'\n",
      " 'positive' 'positive' 'positive' 'negative' 'positive' 'positive'\n",
      " 'positive' 'negative' 'negative' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'negative'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'negative' 'negative' 'negative'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'negative' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'negative' 'positive' 'negative'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'negative' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'negative' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'negative' 'positive' 'positive' 'positive' 'positive'\n",
      " 'negative' 'positive' 'negative' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'negative' 'negative' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'negative' 'negative' 'positive' 'positive'\n",
      " 'positive' 'negative' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'negative' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'negative' 'positive' 'negative' 'negative' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'negative'\n",
      " 'positive' 'positive' 'negative' 'positive' 'positive' 'positive'\n",
      " 'negative' 'negative' 'positive' 'positive' 'positive' 'negative'\n",
      " 'positive' 'positive' 'positive' 'negative' 'negative' 'negative'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'negative' 'positive'\n",
      " 'positive' 'positive' 'negative' 'positive' 'negative' 'positive'\n",
      " 'negative' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'negative' 'negative' 'positive' 'positive' 'positive' 'positive'\n",
      " 'negative' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'negative' 'positive' 'positive' 'negative'\n",
      " 'positive' 'negative' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'negative'\n",
      " 'positive' 'negative' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'negative' 'negative' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'negative' 'positive' 'positive' 'positive'\n",
      " 'negative' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'negative' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'negative'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'negative' 'positive' 'positive' 'negative'\n",
      " 'negative' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'negative' 'positive' 'positive' 'positive'\n",
      " 'negative' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'negative' 'positive' 'positive'\n",
      " 'positive' 'positive' 'negative' 'positive' 'negative' 'positive'\n",
      " 'negative' 'positive' 'negative' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'negative' 'positive' 'positive' 'negative'\n",
      " 'positive' 'positive' 'positive' 'negative' 'negative' 'negative'\n",
      " 'negative' 'negative' 'negative' 'negative' 'positive' 'negative'\n",
      " 'negative' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'negative' 'negative' 'positive' 'positive' 'positive'\n",
      " 'negative' 'negative' 'negative' 'negative' 'positive' 'positive'\n",
      " 'positive' 'negative' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'negative' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'negative'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'negative' 'negative' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'negative' 'negative'\n",
      " 'negative' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'negative' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'negative' 'positive' 'positive' 'negative' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'negative' 'positive' 'negative' 'positive' 'positive'\n",
      " 'negative' 'negative' 'positive' 'negative' 'positive' 'positive'\n",
      " 'negative' 'positive' 'positive' 'positive' 'negative' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'negative'\n",
      " 'positive' 'negative' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'negative' 'positive' 'positive' 'positive'\n",
      " 'negative' 'negative' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'negative' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'negative' 'negative' 'negative' 'negative'\n",
      " 'positive' 'positive' 'positive' 'negative' 'positive' 'positive'\n",
      " 'negative' 'positive' 'negative' 'positive' 'positive' 'positive'\n",
      " 'positive' 'negative' 'positive' 'positive' 'negative' 'negative'\n",
      " 'positive' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'negative' 'positive' 'negative' 'negative' 'positive'\n",
      " 'negative' 'positive' 'positive' 'positive' 'negative' 'negative'\n",
      " 'negative' 'positive' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'negative' 'positive' 'negative' 'positive' 'positive'\n",
      " 'positive' 'positive' 'negative' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'negative' 'negative' 'positive' 'positive'\n",
      " 'positive' 'negative' 'positive' 'positive' 'positive' 'positive'\n",
      " 'positive' 'positive' 'positive' 'positive' 'negative' 'negative'\n",
      " 'positive' 'positive' 'positive' 'negative' 'positive' 'positive'\n",
      " 'negative' 'negative' 'negative' 'positive' 'negative' 'positive'\n",
      " 'negative' 'positive' 'negative' 'positive' 'positive' 'positive']\n"
     ]
    }
   ],
   "source": [
    "#Predicting the model for TF\n",
    "predict = regressor.predict(test_reviews)\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_tfidf_score : 0.6216216216216216\n"
     ]
    }
   ],
   "source": [
    "#Accuracy score for TF\n",
    "score = accuracy_score(y_test,predict)\n",
    "print(\"lr_tfidf_score :\",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.79      0.35      0.48       339\n",
      "    Negative       0.57      0.91      0.70       327\n",
      "\n",
      "   micro avg       0.62      0.62      0.62       666\n",
      "   macro avg       0.68      0.63      0.59       666\n",
      "weighted avg       0.68      0.62      0.59       666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Summary Report\n",
    "report = classification_report(y_test, predict, target_names=['Positive','Negative'])\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
